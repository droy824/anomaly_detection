{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Jx6kWLEs6MTzQLSX3Gw_9b0l1D3_W7dx","timestamp":1714726692375},{"file_id":"15olJd8WzwbsQ9MGgTsQ2Ja_CJlciupTa","timestamp":1714696205803},{"file_id":"1WleX6O3ABL1In7hzUydOMi04Z8CUnBra","timestamp":1714666575354}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Classes:**\n","*Abuse*, arrest, *assault*, burglary, fighting, road accidents, shooting, shoplifting, vandalism, normal.\n","\n","Out of: **abuse**, **arrest**, arson, **assault**, burglary, **fighting**, **roadaccidents**, **robbery**, **shooting**, shoplifting, **stealing**, **vandalism**, **normal**"],"metadata":{"id":"ykwKhhxOmIPE"}},{"cell_type":"markdown","source":["**Train-test split:**\n","\n","No. of videos in train dataset: 224\n","\n","No. of normal videos in train dataset: 123\n","\n","Ratio: 0.549\n","\n","No. of videos in test dataset: 47\n","\n","No. of normal videos in test dataset: 26\n","\n","Ratio: 0.553\n","\n","**Train-test split = 80:20**"],"metadata":{"id":"55sUBPUWq1-a"}},{"cell_type":"markdown","source":["\n","# Load anomaly class folder"],"metadata":{"id":"cVV1nTeGqbTf"}},{"cell_type":"code","source":["# @title Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsJTnbfmWya0","executionInfo":{"status":"ok","timestamp":1715542928460,"user_tz":-330,"elapsed":68272,"user":{"displayName":"STUTI SINHA","userId":"14684302027454441121"}},"outputId":"de068089-328a-42d3-b2a3-67c57dd19784"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# @title Unzip uploaded folder in Colab\n","!unzip \"/content/drive/MyDrive/anomaly_detection/Test_dataset_2.zip\" -d \"/content/Test_dataset_2_unzipped\""],"metadata":{"id":"Xzxyl-n3rDCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pytorchyolo"],"metadata":{"id":"IOF0s0YeYMBh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run YOLO"],"metadata":{"id":"wvvyVxGArUzV"}},{"cell_type":"code","source":["# @title Import dependencies\n","import cv2\n","from pytorchyolo import detect, models\n","import torch\n","import torchvision\n","from torchvision.io import read_image\n","from torchvision.utils import draw_bounding_boxes\n","import numpy as np\n","from PIL import Image"],"metadata":{"id":"OpDvsiZbY3f8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv2.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Z-vCHNkfbYC2","executionInfo":{"status":"ok","timestamp":1714571647458,"user_tz":-330,"elapsed":8,"user":{"displayName":"DEEPAN ROY","userId":"10531759322214537254"}},"outputId":"632b13a6-9170-4654-88e9-7c0f832460fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# Run Deep SORT"],"metadata":{"id":"yFSmdLQorXQh"}},{"cell_type":"code","source":["!git clone https://github.com/abhyantrika/nanonets_object_tracking/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvJZdiaigWjz","executionInfo":{"status":"ok","timestamp":1715543035152,"user_tz":-330,"elapsed":1933,"user":{"displayName":"STUTI SINHA","userId":"14684302027454441121"}},"outputId":"7d697752-51e0-4f98-953d-b61e998ff1dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nanonets_object_tracking'...\n","remote: Enumerating objects: 125, done.\u001b[K\n","remote: Counting objects: 100% (46/46), done.\u001b[K\n","remote: Compressing objects: 100% (35/35), done.\u001b[K\n","remote: Total 125 (delta 21), reused 11 (delta 11), pack-reused 79\u001b[K\n","Receiving objects: 100% (125/125), 13.59 MiB | 17.70 MiB/s, done.\n","Resolving deltas: 100% (36/36), done.\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/anomaly_detection/nanonets_object_tracking-master')"],"metadata":{"id":"91zo4V7MtXWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/anomaly_detection/nanonets_object_tracking-master\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9t8JwsUIt1oS","executionInfo":{"status":"ok","timestamp":1714678110226,"user_tz":-330,"elapsed":3,"user":{"displayName":"STUTI SINHA","userId":"14684302027454441121"}},"outputId":"a44a17da-7780-49f7-e113-26861d5c294e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ckpts\t     det\t    README.md\t      siamese_dataloader.py  siamese_train.py\n","deep_sort    get_images.py  requirements.txt  siamese_net.py\t     test_on_video.py\n","deepsort.py  __pycache__    roi.jpg\t      siamese_test.py\n"]}]},{"cell_type":"code","source":["import torchvision.utils\n","import numpy as np\n","import cv2\n","import csv\n","from deepsort import *"],"metadata":{"id":"gGia8s3XqxmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_gt(image,frame_id,gt_dict):\n","\t# print(\"IN GET_GT\")\n","\tif frame_id not in gt_dict.keys() or gt_dict[frame_id]==[]:\n","\t\treturn None,None\n","\n","\tframe_info = gt_dict[frame_id]\n","\n","\tdetections = []\n","\tids = []\n","\tout_scores = []\n","\tfor i in range(len(frame_info)):\n","\n","\t\tcoords = frame_info[i]['coords']\n","\n","\t\tx1,y1,x2,y2 = coords\n","\t\tw = x2 - x1\n","\t\th = y2 - y1\n","\t\t# x2 = x1 + w\n","\t\t# y2 = y1 + h\n","\n","\t\t# xmin = min(x1,x2)\n","\t\t# xmax = max(x1,x2)\n","\t\t# ymin = min(y1,y2)\n","\t\t# ymax = max(y1,y2)\n","\n","\t\tdetections.append([x1,y1,w,h])\n","\t\tout_scores.append(frame_info[i]['conf'])\n","\n","\treturn detections,out_scores\n","\n","\n","def get_dict(filename):\n","\twith open(filename) as f:\n","\t\td = f.readlines()\n","\n","\td = list(map(lambda x:x.strip(),d))\n","\n","\tlast_frame = int(d[-1].split(',')[0])\n","\n","\tgt_dict = {x:[] for x in range(last_frame+1)}\n","\n","\tfor i in range(len(d)):\n","\t\ta = list(d[i].split(','))\n","\t\ta = list(map(float,a))\n","\n","\t\tcoords = a[2:6]\n","\t\tconfidence = a[6]\n","\t\tgt_dict[a[0]].append({'coords':coords,'conf':confidence})\n","\n","\treturn gt_dict\n","\n","def get_mask(filename):\n","\tmask = cv2.imread(filename,0)\n","\tmask = mask / 255.0\n","\treturn mask"],"metadata":{"id":"YNuGlmI_qsoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anomaly_map = {'Abuse':0,\n","               'Arrest':1,\n","               'Assault':2,\n","               'Burglary':3,\n","               'Fighting':4,\n","               'Normal':5,\n","               'RoadAccidents':6,\n","               'Shooting':7,\n","               'Shoplifting':8,\n","               'Vandalism':9}"],"metadata":{"id":"Uv7Ip5WdnxFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def annotations(vid_file_name):\n","  # anno_file = open('/content/drive/MyDrive/anomaly_detection/Temporal_Anomaly_Annotation_for_Testing_Videos.txt', 'r')\n","  # annotations = anno_file.read()\n","  # annotations = annotations.split(\"\\n\")\n","  # for i in range(291):\n","  #   annotations[i] = annotations[i].split('  ')\n","  # for annotation in annotations:\n","  #   # print(annotation)\n","  #   if annotation[0] == vid_file_name:\n","  #     anomaly_class = anomaly_map[annotation[1]]\n","  #     result = [int(annotation[2]), int(annotation[3]), anomaly_class] # Returns result: [anomaly_start_frame, anomaly_end_frame, anomaly_type]\n","  # anno_file.close()\n","  result = []\n","\n","  classes_dict = {}\n","  classes_file_name = \"/content/drive/MyDrive/anomaly_detection/det/classes_{}.txt\".format(vid_file_name)\n","  classes_file = open(classes_file_name, 'r')\n","  classes = classes_file.readlines()\n","  classes_file.close()\n","  # classes = classes.split(\"\\n\")\n","  # Need to get obj class from classes file\n","  for frame_class in classes:\n","    frame_class = frame_class.split(',')\n","    classes_dict[int(frame_class[0])] = float(frame_class[1])\n","\n","  return result, classes_dict\n","\n","# result, classes_dict = annotations(\"Abuse028_x264.mp4\")\n","# result\n","# classes_dict"],"metadata":{"id":"BDIxsKd_Cwja"},"execution_count":null,"outputs":[]},{"source":["import re\n","\n","def extract_anomaly_type(filename):\n","  \"\"\"\n","  Extracts the anomaly type from a filename.\n","\n","  Args:\n","    filename: The filename to extract the anomaly type from.\n","\n","  Returns:\n","    The anomaly type, or None if not found.\n","  \"\"\"\n","\n","  match = re.search(r'^(\\D+)', filename)\n","  if match:\n","    anomaly_type = match.group(1)\n","    if anomaly_type == 'Normal_Videos_':\n","      return anomaly_map['Normal']\n","    else:\n","      return anomaly_map[anomaly_type]\n","  else:\n","    return None\n","\n","# filename = 'Normal_Videos_910_x264.mp4'\n","# anomaly_type = extract_anomaly_type(filename)\n","# print(anomaly_type)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qJacHDNY9pN","executionInfo":{"status":"ok","timestamp":1715543063732,"user_tz":-330,"elapsed":739,"user":{"displayName":"STUTI SINHA","userId":"14684302027454441121"}},"outputId":"86cd09e4-6e63-4bba-e8fb-f7044470a391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n"]}]},{"cell_type":"code","source":["# @title Run YOLO and DeepSORT to generate detection files for each video\n","\n","import os\n","\n","# CONFIG_PATH = \"/Users/deepan_roy/Documents/2-2/SOP/PyTorch-YOLOv3-master/config/yolov3.cfg\"\n","# WEIGHTS_PATH = \"/Users/deepan_roy/Documents/2-2/SOP/PyTorch-YOLOv3-master/yolov3.weights\"\n","CONFIG_PATH = \"/content/drive/MyDrive/anomaly_detection/YOLOv3/yolov3.cfg\"\n","WEIGHTS_PATH = \"/content/drive/MyDrive/anomaly_detection/YOLOv3/yolov3.weights\"\n","\n","# Load the YOLO model\n","model = models.load_model(\n","  CONFIG_PATH,\n","  WEIGHTS_PATH)\n","\n","# vid_name = \"Abuse028_x264.mp4\"\n","PATH = '/content/Test_dataset_2_unzipped/Test_dataset_2/'\n","for vid_name in l2:\n","  vidfile = PATH + vid_name\n","  print(vidfile + '...')\n","  cap = cv2.VideoCapture(vidfile)\n","  fps = cap.get(cv2.CAP_PROP_FPS)\n","  print(\"Number of frames: {}\".format(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n","\n","  pred_cnt = 0\n","  detections = \"\"\n","  classes = \"\"\n","  while cap.isOpened():\n","      is_read, frame = cap.read()\n","      if is_read:\n","          pos_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n","          boxes = detect.detect_image(model, frame)\n","          boxes = np.asarray(boxes)\n","          for box in boxes:\n","                detections += \"{},-1,{},{},{},{},{},-1,-1,-1\\n\".format(pos_frame, box[0], box[1], box[2], box[3], box[4])\n","                classes += \"{},{}\\n\".format(pos_frame, box[5])\n","          # print(\"{}... \".format(pos_frame))\n","      else:\n","          # cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n","          cv2.waitKey(1000)\n","          print(\"Error\")\n","      if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n","          # If the number of captured frames is equal to the total number of frames, we stop\n","          break\n","      if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n","          break\n","  cap.release()\n","  cv2.destroyAllWindows()\n","  # print(detections)\n","\n","  det_path = \"/content/drive/MyDrive/anomaly_detection/det\" + \"/det_{}.txt\".format(vid_name)\n","  with open(det_path, 'w') as det_file:\n","      det_file.write(detections)\n","  classes_path = \"/content/drive/MyDrive/anomaly_detection/det\" + \"/classes_{}.txt\".format(vid_name)\n","  with open(classes_path, 'w') as classes_file:\n","      classes_file.write(classes)\n","\n","\n","\n","  # ========== DEEPSORT ==============\n","\n","\n","\n","\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Select device for inference\n","\n","  #Load detections for the video. Options available: yolo,ssd and mask-rcnn\n","  # vid_name = \"Abuse028_x264.mp4\"\n","  det_file_name = \"/content/drive/MyDrive/anomaly_detection/det/det_{}.txt\".format(vid_name)\n","  gt_dict = get_dict(det_file_name)\n","  # print(gt_dict)\n","\n","  cap = cv2.VideoCapture(PATH + vid_name)\n","\n","  #Initialize deep sort.\n","  deepsort = deepsort_rbc(wt_path='/content/drive/MyDrive/anomaly_detection/nanonets_object_tracking-master/ckpts/model640.pt')\n","\n","  # deepsort.metric = deepsort.metric.to(device)\n","  # deepsort.tracker = deepsort.tracker.to(device)\n","  deepsort.gaussian_mask = deepsort.gaussian_mask.to(device)\n","  # deepsort.transforms = deepsort.transforms.to(device)\n","  # print(deepsort.metric.is_cuda)\n","  # print(deepsort.tracker.is_cuda)\n","  # print(deepsort.gaussian_mask.is_cuda)\n","  # print(deepsort.transforms.is_cuda)\n","\n","  frame_id = 1\n","\n","\n","  anomaly_info, classes = annotations(vid_name)\n","\n","  inputs = []\n","\n","  while True:\n","    print(frame_id)\n","\n","    ret,frame = cap.read()\n","    if ret is False:\n","      frame_id+=1\n","      break\n","\n","    # frame = frame * mask\n","    frame = frame.astype(np.uint8)\n","    detections,out_scores = get_gt(frame,frame_id,gt_dict)\n","\n","    if detections is None:\n","      print(\"No dets\")\n","      frame_id+=1\n","      continue\n","\n","    detections = np.array(detections)\n","    out_scores = np.array(out_scores)\n","    # print(len(detections) == 0)\n","    tracker,detections_class = deepsort.run_deep_sort(frame,out_scores,detections)\n","\n","    for track in tracker.tracks:\n","      if not track.is_confirmed() or track.time_since_update > 1:\n","        continue\n","\n","      bbox = track.to_tlbr() #Get the corrected/predicted bounding box\n","      id_num = str(track.track_id) #Get the ID for the particular track.\n","      features = track.features #Get the feature vector corresponding to the detection.\n","\n","      pos_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n","\n","      # Read class for the frame in the current file from classes file\n","      obj_class = classes[pos_frame] if pos_frame in classes else -1\n","      # Read anomaly type, anomalous frame numbers from annotations file for the current file\n","      # anomaly_in_frame = anomaly_info[2] if pos_frame in range(anomaly_info[0], (anomaly_info[1] + 1)) else 5\n","      anomaly_in_frame = extract_anomaly_type(vid_name)\n","\n","      input = [pos_frame, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3], obj_class, anomaly_in_frame]\t# How to add class and anomaly?\n","      inputs.append(input)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","\n","    frame_id+=1\n","\n","  csv_file_name = '/content/drive/MyDrive/anomaly_detection/Test/test_{}.csv'.format(vid_name)\n","  fields = ['frame_num', 'track_id', 'x_min', 'y_min', 'x_max', 'y_max', 'object_class', 'anomaly_in_frame']\n","\n","  with open(csv_file_name, 'w') as csvfile:\n","      # creating a csv writer object\n","      csvwriter = csv.writer(csvfile)\n","\n","      # writing the fields\n","      csvwriter.writerow(fields)\n","\n","      # writing the data rows\n","      csvwriter.writerows(inputs)\n","  print('test_{}.csv done'.format(vid_name))\n","\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"IavS_KdhqKCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # @title Run Deep SORT to generate input CSV files for LSTM\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Select device for inference\n","\n","# #Load detections for the video. Options available: yolo,ssd and mask-rcnn\n","# vid_name = \"Abuse028_x264.mp4\"\n","# det_file_name = \"/content/drive/MyDrive/anomaly_detection/det/det_{}.txt\".format(vid_name)\n","# gt_dict = get_dict(det_file_name)\n","# # print(gt_dict)\n","\n","# cap = cv2.VideoCapture('/content/drive/MyDrive/anomaly_detection/{}'.format(vid_name))\n","\n","# #Initialize deep sort.\n","# deepsort = deepsort_rbc(wt_path='/content/drive/MyDrive/anomaly_detection/nanonets_object_tracking-master/ckpts/model640.pt')\n","\n","# # deepsort.metric = deepsort.metric.to(device)\n","# # deepsort.tracker = deepsort.tracker.to(device)\n","# deepsort.gaussian_mask = deepsort.gaussian_mask.to(device)\n","# # deepsort.transforms = deepsort.transforms.to(device)\n","# # print(deepsort.metric.is_cuda)\n","# # print(deepsort.tracker.is_cuda)\n","# print(deepsort.gaussian_mask.is_cuda)\n","# # print(deepsort.transforms.is_cuda)\n","\n","# frame_id = 1\n","\n","\n","# anomaly_info, classes = annotations(vid_name)\n","\n","# inputs = []\n","\n","# while True:\n","# \tprint(frame_id)\n","\n","# \tret,frame = cap.read()\n","# \tif ret is False:\n","# \t\tframe_id+=1\n","# \t\tbreak\n","\n","# \t# frame = frame * mask\n","# \tframe = frame.astype(np.uint8)\n","# \tdetections,out_scores = get_gt(frame,frame_id,gt_dict)\n","\n","# \tif detections is None:\n","# \t\tprint(\"No dets\")\n","# \t\tframe_id+=1\n","# \t\tcontinue\n","\n","# \tdetections = np.array(detections)\n","# \tout_scores = np.array(out_scores)\n","# \tprint(len(detections) == 0)\n","# \ttracker,detections_class = deepsort.run_deep_sort(frame,out_scores,detections)\n","\n","# \tfor track in tracker.tracks:\n","# \t\tif not track.is_confirmed() or track.time_since_update > 1:\n","# \t\t\tcontinue\n","\n","# \t\tbbox = track.to_tlbr() #Get the corrected/predicted bounding box\n","# \t\tid_num = str(track.track_id) #Get the ID for the particular track.\n","# \t\tfeatures = track.features #Get the feature vector corresponding to the detection.\n","\n","# \t\tpos_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n","\n","# \t\t# Read class for the frame in the current file from classes file\n","# \t\tobj_class = classes[pos_frame] if pos_frame in classes else -1\n","# \t\t# Read anomaly type, anomalous frame numbers from annotations file for the current file\n","# \t\tanomaly_in_frame = anomaly_info[2] if pos_frame in range(anomaly_info[0], (anomaly_info[1] + 1)) else 5\n","# \t\tinput = [pos_frame, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3], obj_class, anomaly_in_frame]\t# How to add class and anomaly?\n","# \t\tinputs.append(input)\n","\n","# \tif cv2.waitKey(1) & 0xFF == ord('q'):\n","# \t\tbreak\n","\n","# \tframe_id+=1\n","\n","# csv_file_name = '/content/drive/MyDrive/anomaly_detection/Inputs/input_{}.csv'.format(vid_name)\n","# fields = ['frame_num', 'track_id', 'x_min', 'y_min', 'x_max', 'y_max', 'object_class', 'anomaly_in_frame']\n","\n","# with open(csv_file_name, 'w') as csvfile:\n","#     # creating a csv writer object\n","#     csvwriter = csv.writer(csvfile)\n","\n","#     # writing the fields\n","#     csvwriter.writerow(fields)\n","\n","#     # writing the data rows\n","#     csvwriter.writerows(inputs)"],"metadata":{"id":"P9enDWCRqPQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # l = ['Abuse005_x264.mp4',\n","# #   'Arrest003_x264.mp4',\n","# #   'Assault002_x264.mp4',\n","# #   'Burglary001_x264.mp4',\n","# #   'Burglary002_x264.mp4',\n","# #   'Burglary003_x264.mp4',\n","# #   'Fighting011_x264.mp4',\n","# #   'Normal_Videos_015_x264.mp4',\n","# #   'Normal_Videos_050_x264.mp4',\n","# #   'Normal_Videos_100_x264.mp4',\n","# #   'Normal_Videos_907_x264.mp4',\n","# #   'Normal_Videos_908_x264.mp4',\n","# #   'Normal_Videos_909_x264.mp4',\n","# #   'Normal_Videos_910_x264.mp4',\n","# #   'Normal_Videos_911_x264.mp4',\n","# #   'Normal_Videos_912_x264.mp4',\n","# #   'Normal_Videos_913_x264.mp4',\n","# #   'Normal_Videos_914_x264.mp4',\n","# #   'Normal_Videos_915_x264.mp4',\n","# #   'Normal_Videos_923_x264.mp4',\n","# #   'Normal_Videos_924_x264.mp4',\n","# #   'Normal_Videos_925_x264.mp4',\n","# #   'Normal_Videos_926_x264.mp4',\n","# #   'Normal_Videos_927_x264.mp4',\n","# #   'Normal_Videos_928_x264.mp4']\n","# for f in l:\n","#   print(f, \":\", extract_anomaly_type(f))"],"metadata":{"id":"VHKn4nPQXJtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","\n","# l = os.listdir(\"/content/Test_dataset_2_unzipped/Test_dataset_2\")\n","# done = os.listdir(\"/content/drive/MyDrive/anomaly_detection/Test\")\n","# l = sorted(l)\n","# l2 = [i for i in l if \"Normal\" not in i and \"test_\"+i+\".csv\" not in done and i != \".DS_Store\"]\n","# l2"],"metadata":{"id":"5xk-qGy9B_v8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# c = 0\n","# l = []\n","# # for i in sorted(os.listdir(\"/content/drive/MyDrive/anomaly_detection/Inputs\")):\n","# #   if 'Normal' in i:\n","# #     # print(i)\n","# #     l.append(i)\n","# #     c += 1\n","# # # print(len(l))\n","# # l\n","# # c\n","# (sorted(os.listdir(\"/content/drive/MyDrive/anomaly_detection/Test\")))"],"metadata":{"id":"jeGW4FBHw-wW"},"execution_count":null,"outputs":[]}]}